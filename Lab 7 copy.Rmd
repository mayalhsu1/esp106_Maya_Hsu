---
title: "Lab 7_Solutions"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
path <- "/Users/mayahsu/Desktop/school/environmental data science/"

knitr::opts_knit$set(root.dir = path)
setwd(path)
unzip("week 7/Data.zip")
```

## Lab 7

In this lab we will practice working with raster data, in this case in the context of climate models. I have given you 4 sets of data:

1. Climate Model Data_Historic - this is a NetCDF file with output from a climate model. Data is monthly average air temperature for 1920-2005
2. Climate Model Data_Future - this is a NetCDF file with climate model output for the period 2006-2080
3. Observed Temp Data - this is gridded data based on weather station and satellite data. Data is monthly for 1991-2000
4. Population data - gridded counts of population for a number of years

The first part of the lab will compare modeled and observed climate data for major cities around the world. The second part of the lab will combine the population data and future climate data to project future changes in global temperature. 

#Part 1

1a. Read in the historic climate model data as a SpatRaster. Use "TREFHT" (temperature at reference height) in the subds (sub-dataset) argument.

```{r}
library(terra)
historic <- rast("week 7/Data/Climate Model Data_Historic/b.e11.B20TRC5CNBDRD.f09_g16.002.cam.h0.TREFHT.192001-200512.nc", "TREFHT")
```

1b. Use ext() to see the longitude and latitude range of the SpatRaster you created. Note that the longitude goes form 0 to 360 (ish) instead of the more typical -180 to 180. This will cause a problem later on so use the rotate() function to change the longitude coordinates. Use extent again on the rotated object to check the longitude goes from -180 to 180 (ish)

```{r}
historic <- rotate(historic) #extent changed from 0 to 360 to -180 to 180, checked extent using extent(historic) before and after rotating
```

2a. Use `rnaturalearth::ne_download()` function to get a sf object of major cities ("populated_places"). Use `vect` to coerce this to a SpatVector, and subset it to get just the 10 most populous cities based on 2020 population (POP2020 column)

```{r}
#Hint 1: Check the object type of the POP2020 column. If necessary convert to a numeric vector using as.numeric()

#Hint 2: The function order() will give you the index value corresponding to the ascending or descending numerical order of a column

library(rnaturalearth)
rnaturalearth::ne_download()
cities <- vect(ne_download(scale = 110, "populated_places", returnclass = "sf")) #creating a spatial vector of cities
as.numeric(cities$POP2020) #changing population to a numeric value
pop20 <- cities[order(cities$POP2020, decreasing = TRUE)] #ordering the spatial vector from most to least populated cities
pop20 <- pop20[1:10] #indexing for the top 10 most populated cities
topnames <- pop20$NAME[1:10] #creating a 
pop20$NAME[1:10] #getting the names of the top 10 most populated cities
```

2b. Make a plot of the temperature data for January 1920 and overlay the 10 major cities.

```{r}
time_index <- time(historic, format = "days") #creating a time index with the date of each entry from the historic climate model
historic_1920 <- subset(historic, (time(historic, format = "days") == "1920-02-01")) #creating a subsetted spatial rastor for February 1920 because there is no data for January 1920
plot(historic_1920, main = "Temperature Data for the Most Populated Cities in\nFebruary 1920 (in Kelvin)")
plot(pop20, add = TRUE)
```

2c. What about the plot gives you confidence this is actually showing temperature data from a January? What are the units of the temperature data?

**Answer: The units are in Kelvin. The units were given for the SpatRaster before we rotated it, and the numbers on the scale for the plot in part 2b suggest that the units are in Kelvin**

3a. Read in the observed temperature data as a SpatRaster, using "tmp" for the sub-dataset argument

```{r}
observed <- rast("/Users/mayahsu/Desktop/school/environmental data science/week 7/Data/Observed Temp Data/cru_ts4.03.1991.2000.tmp.dat.nc", "tmp")
```

3b. Note that this climate model data is for 1920-2005 but the observation data is only from 1991-2000. Subset the climate model data to just the years 1991-2000. Also change the units to match those of the observed climate data.

```{r}
# hint: have a look at ?terra::time to see how to get years
time_index <- time(historic, format = "years") #creating a time index with the year of each entry from the historic climate model
historic_subset <- subset(historic, time_index >= 1991 & time_index <= 2000) #subsetting for years between (and including) 1991 and 2000, when time_index is TRUE those observations will be selected
historic_subset <- historic_subset - 273.15 #changing units to celsius
```

4. Use terra::extract() to produce two data-frames, one with observed and one with modeled temperature values for each city. Change the units of the modeled data so they match the units of the observed data.

```{r}
city_obs <- extract(observed, pop20, ID = FALSE) #removing the ID row so that the number of entries will be the same as for the time data later on
city_sim <- extract(historic_subset, pop20, ID = FALSE)
```

We have to do a bit of data-wrangling to compare modeled and observed temperature data for each city.

5a. Add a column to both data-frames with the names of the cities using the NAME column from the city data frame

```{r}
city_obs <- data.frame(t(city_obs)) #transposing data
city_sim <- data.frame(t(city_sim))
colnames(city_obs) <- topnames #changing to column names to the top 10 most populated cities
colnames(city_sim) <- topnames
city_obs$time <- time(observed, format = "days") #adding a column for date
city_sim$time <- time(historic_subset, format = "days")
```

5b. Use pivot_longer() from the tidyr package to turn both data-frames into tidy data-frames, with one row for each unique city-month combination

```{r}
#Hint: you want to use the first 10 columns (cities) to pivot (cols argument in the pivot_longer function). Use the values_to argument to name the temperature data column either "observed" or "simulated".

library(tidyr)
extract <- terra::extract #setting extract function to terra package
city_obs <- pivot_longer(city_obs, cols = all_of(topnames)) #pivoting top column so that each entry is a row 
colnames(city_obs) <- c("Date", "City", "Observed")
city_sim <- pivot_longer(city_sim, cols = all_of(topnames))
colnames(city_sim) <- c("Date", "City", "Simulated")
```

5c. Notice that the modeled and observed rasters have used slightly different conventions for naming the months. You can see this in the "name" column of the two data frames you made in 5b. The model output uses the first of the month (e.g. 1991.02.01) whereas the observational data uses the middle of the month (e.g. 1991.01.16). This is a problem since we want to merge together the two data frames to compare observed and simulated data.

To merge the two data frames together, first we need to "chop off" the last two digits in the month ids in both data frames. One way to do this is to use the substr() function to return some subset of a character vector.

change the variable "time" from Date to "yearmon" (character)

```{r}
city_sim$Date <- substr(city_sim$Date, 1, 7) #by only taking the first through seventh characters of the date, we are left with the year and the month

city_obs$Date <- substr(city_obs$Date, 1, 7)
```

5d. Merge the observed and modeled city data into a single data-frame. In this case you could use `cbind`, but that it is safer to use `merge`

```{r}
#Hint: you will want to specify two columns in the "by" argument in merge(). Think about what two columns those should be (i.e. what combination of columns identifies a unique observation that matches across the two dataframes)

merged <- merge(city_sim, city_obs, by = c("City", "Date"))
```

5e. Make a plot showing observed vs modeled temperature for the 10 cities. Add a 1:1 line which showing the exact match between observed and modeled data. You can use base plot or ggplot.

```{r}
library(ggplot2)
ggplot(merged, aes(x = Observed, y = Simulated, col = City))+
  geom_point()+
  geom_abline(slope = 1)+
  labs(x = "Observed Temperature (Celsius)", y = "Modeled Temperature (Celsius)", title = "Modeled vs. Observed Temperatures for\nTen Most Populated Cities from 1991 to 2000")
#the distance between the line and each point represents the difference between modeled and observed temperatures
```

#Part 2

In the second part of the lab, we will use projections of future temperature change (until 2080) and a map of the distribution of population in 2020 to get global, population-weighted projected warming.

6a. Read in the netCDF file with projected climate model temperature (in the "Climate Model Data_Future" directory) as a SpatRaster. Use the rotate() function again as you did in 1b to transform the coordinates to -180 to 180 and the units to C. Use `subds="TREFHT"`. This has gridded projections of monthly global temperature between 2006 and 2020 under a high-emissions scenario (referred to as RCP8.5).

```{r}
future <- rast("week 7/Data/Climate Model Data_Future/b.e11.BRCP85C5CNBDRD.f09_g16.002.cam.h0.TREFHT.200601-208012.nc", "TREFHT")

future <- rotate(future) #rotating raster to -180 to 180, checking extent before and after rotation using extent(future)
future <- future - 273.15 #changing units to Celsius
```

6b. Compute the projected _annual_ trend in global climate. Use `tapp` for this temporal aggregation.

```{r}
predicted <- tapp(future, index = "years", fun = "mean") #taking the average of the modeled data for each year
```

7a. Read in the netCDF data on population in the "Population" directory as a SpatRaster. (There is only one variable in this netCDF, so you do not need to specify the variable name this time). This is gridded population count at 15 arc minute resolution.

```{r}
population <- rast("week 7/Data/Population/gpw_v4_population_count_adjusted_rev11_15_min.nc")
```

7b. We want only the 5th layer in this SpatRaster, which corresponds to population count in 2020. (Note - I know this from some associated files that came with the netCDF file. Take a look at the csv file in the directory to see this documentation). Pull out just the population in 2020.

```{r}
population2020 <- population[[5]] #indexing for the fifth layer of the raster
```

8a. Now we want to eventually match the population grid to the projected temperature grid. But the problem is that the grid size of the climate model is much larger than the grid size of the population data. How many rows and columns does the climate model data have? And how many rows and columns does the population data have? Use code to show that.

```{r}
dim(future)
dim(population2020)
```


8b. To fix this problem we can aggregate the population raster up to the resolution of the climate model using the aggregate() function. The population data you have is the population count (i.e. number of people in each grid cell). What function should we use to aggregate to larger grid cells? What function would we use instead if we had population density data instead of population count?

**Answer: To aggregate larger grid cells with population count, use sum. To aggregate population denisty data, use mean.**

8c. Aggregate the population data to a higher level of resolution, as close as possible to the climate model data.

```{r}
popagg <- aggregate(population2020, fact = c(4, 5), fun = "sum") #the values after fact tell the function by what factor to aggregate the rows and columns in popagg
dim(popagg)
```

8d. If everything has gone according to plan, we would expect that summing up all the cells in the population raster should give us something close to the current population on the planet. Calculate that sum from your aggregated population data and compare to the total population today.

```{r}
global(population2020, "sum", na.rm = TRUE)
```

**Answer: 7757982600**

9a. Now we will use the population data to do a weighted averaging of the projected temperature data, to get the monthly temperature experienced by the average person between 2006 and 2080. 

One problem is that even after the aggregation, the grids of the population data still don't quite match. Use terra::resample() to resample the aggregated population data to the climate model grid. 

```{r}
pop2020 <- terra::resample(population2020, future)
dim(pop2020)
```

9b. Now we can use the population raster to do a weighted average of the climate model data. Use the global() function to calculate both the global and and the population-weighted average temperature for each year. 

```{r}
temp <- global(predicted, "mean", na.rm = TRUE) #using the projected annual temperature data from 6b
weighted_temp <- global(predicted, "mean", weights = pop2020, na.rm = TRUE) #weighting by population so that the average value reflects where people live (more weight given to places in which more people live), result should reflect temperature experienced by average person
```


Make a graph showing the projected annual trend in global climate. On the same graph show the temperature trend for the entire world, and weighted by population. 

```{r}
range <- unique(time(future, format = "years")) #creating an object with a list of years

temp$year <- range #creating a column for year
weighted_temp$year <- range

projected <- merge(temp, weighted_temp, by = "year") #merging the data into one dataframe 

ggplot(projected)+
  geom_point(mapping = aes(x = year, y = mean, color = "blue"))+
  geom_point(mapping = aes(x = year, y = weighted_mean, color = "black"))+
  labs(title = "Projected Annual Global Temperature Trends", x = "Year", y = "Temperature (Celsius)")+
  scale_color_identity(guide = "legend", breaks = c("black", "blue"), name = NULL, labels = c("Temperature Weighted by Population", "Temperature not Weighted by Population"))
```


